---
toc: true
layout: post
description: An introduction to measure-theoretic probability theory - sample spaces, sigma algebras, and probability measures.
categories: [markdown]
title: Probability Theory 1 - The Basics
---

Sometimes when we repeat actions, we achieve different random outcomes - the prototypical examples cited usually being tossing a coin, rolling a die, or any form of gambling.
As mathematicians we would like to design a framework within which we express the uncertainty associated with the outcome.
Modern probability theory emerged in this context in the 17th century through the study of "games of chance" and has since grown due to contribution from important figures such as Andrei Kolmogorov, Andrey Markov, Thomas Bayes, Carl Gauss, and many more.

# Basic definitions

There are a few questions that need to be tackled when first trying to design our definitions:

1. How should we represent outcomes to which we assign probabilities?
1. What kinds of outcomes should we allow in our framework?
1. What is a probability and how can we assign one to an outcome?

We address these problems one a time below.

## Sample spaces

> A **sample space** is a set $\Omega$. An element $\omega \in \Omega$ is called a **sample** and a subset $A \subseteq \Omega$ is called an event.

Intuitively, a sample is an outcome of a random occurance and a sample space is simply the set of all possible outcomes.
Rarely, we can further suppose that $\Omega$ has some additional kind of structure, such as being a metric space or Riemannian manifold.
This allows us to talk about relationships between samples in the context of the intrinsic structure of $\Omega$; however this is far beyond the scope of what we cover in this post.

Here are some examples of how some random phenomena can be represented as a sample space.
- In the case of tossing a coin once, we might have $\Omega = \{\text{heads}, \text{tails}\}$.
- If we were studying the annual number of traffic accidents at a busy intersection, we would have $\Omega = \N_0$.
- If we were randomly throwing darts at a square dart board of unit side length, then we could have $\Omega = [0,1] \times [0,1]$, where $\omega \in \Omega$ would represent the location on the board where the dart lands.

As can be seen from the examples, beginning with a set gives us a lot of flexibility in the kinds of randomness we can model.

## Sigma Algebras

Given the definition of an event, we can use the language of set operations to express more complicated outcomes.
For example, in the second example, if $A_n := \{n\}$ for every $n \geq 0$, then $A := \bigcup_{n \geq 0} A_{2n}$ is the event that an even number of accidents occur.
On the other hand, in the third example, if $B := [0,1/2] \times [0,1]$ and $C := [0,1] \times [0,1/2]$, then $D := B \cap C = [0,1/2] \times [0,1/2]$ would be the vent that the dart lands in the bottom-left quadrant of the board.

This leads us to the answer of the second question.
In theory, we may choose to allow any set in $\mathcal P(\Omega)$

## Probability measures


This leads us to the answer of the next question.
In theory, we may choose to allow any subset of \P(\Omega).
Since it is useful to speak about events as in the way, it makes sense to define the following.

A \sigma-algebra is a collection of subsets \F \subset \P(\Omega) such that the following hold:
1) \Omega \in \F
2) if A \in \F, then A^c := \Omega \setminus A \in \F
3) if {A_n : n \geq 1} is a sequence of events with A_n \in \F for every n \geq 1, then A := \bigcup_{n \geq 1} A_n \in F

Note that using 2), 3), and De Morgan's laws, we obtain
3') if {A_n : n \geq 1} is a sequence of events with A_n \in \F for every n \geq 1, then A := \bigcap_{n \geq 1} A_n \in F
and in fact, a \sigma-algebra can be equivalently defined using 3') instead of 3).

Intuitively, \F represents the kinds of events we are able to observe from a random occurance.

Usually, at first glance of the definition of a \sigma-algebra, it seems confusing as to why we don't allow for uncountable unions in 3).
Before explaining why it is necessary to restrict ourselves in this way, let's finally define what exactly is a probability.

A probability measure (or simply a probability) is a function \P : \F \to [0,1] that satisfies the following:
1) (Non-negativity) For any A \in \F, \P(A) \geq 0
2) (Boundedness) \P(\Omega) = 1
3) (countable additivity) If {A_n : n \geq 1} is a sequence of DISJOINT events with A_n \in \F for every n \geq 1, then \P(\bigcup_{n \geq 1} A_n) = \sum_{n \geq 1} \P(A_n)

Given \Omega, \F, and \P as defined above, a triple (\Omega, \F, \P) is called a probabilty space.

For example,
- In the first example, we have \Omega = \{H, T\}, \F = \{\emptyset, \{H\}, \{T\}, \Omega\}, and \P(\{H\}) = \P{\{T\}} = 1/2
- In the third example, we have \Omega = [0,1] \times [0,1], \F is the set of borel-measurable subsets of \Omega, and \P = \lambda is Lebesgue measure.

If we allow uncountable unions in the definition of a \sigma-algebra, then given a probability measure, it is possible to a build an event with probability strictly greater than one.
In other words, it would break our otherwise very nice definition of a probability measure.
We'll explain this shortcoming more in-depth in a later post.

At last, we finally have the basic ground work on which we can build more probability theory.
To end, here are some properties of \P which follow directly from the definition and set operation.
It's a good exercise to try proving them!

-\P(A^c) = 1 - \P(A)
-\P(\emptyset) = 0
-(monotonicity) if A \subseteq B, then \P(A) \leq \P(B)
-(sub-additivity) Given a sequence of events \{A_n : n \geq 1\} which may not necessarily be disjoint, \P(\bigcup_{n \geq 1} A_n) \leq \sum_{n \geq 1} \P(A_n)
-(Continuity from below) Given \{A_n : n \geq 1\} with A_n \subseteq A_{n+1} then \P(\bigcup_{n \geq 1} A_n) = \lim_{n \to \infty} \P(A_n)
-(Continuity from above) Given \{A_n : n \geq 1\} with A_{n+1} \subseteq A_n then \P(\bigcap_{n \geq 1} A_n) = \lim_{n \to \infty} \P(A_n)
