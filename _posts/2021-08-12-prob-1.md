---
toc: true
layout: post
description: An introduction to measure-theoretic probability theory - sample spaces, sigma algebras, and probability measures.
categories: [markdown]
title: Probability Theory 1 - The Basics
---

Sometimes when we repeat actions, we achieve different random outcomes - the prototypical examples cited usually being tossing a coin, rolling a die, or any form of gambling.
As mathematicians we would like to design a framework within which we express the uncertainty associated with the outcome.
Modern probability theory emerged in this context in the 17th century through the study of "games of chance" and has since grown due to contribution from important figures such as Andrei Kolmogorov, Andrey Markov, Thomas Bayes, Carl Gauss, and many more.

# Basic definitions

There are a few questions that need to be tackled when first trying to design our definitions:

1. How should we represent outcomes to which we assign probabilities?
1. What kinds of outcomes should we allow in our framework?
1. What is a probability and how can we assign one to an outcome?

We address these problems one a time below.

## Sample spaces

> A **sample space** is a set $\Omega$. An element $\omega \in \Omega$ is called a **sample** and a subset $A \subseteq \Omega$ is called an event.

Intuitively, a sample is an outcome of a random occurance and a sample space is simply the set of all possible outcomes.
Rarely, we can further suppose that $\Omega$ has some additional kind of structure, such as being a metric space or Riemannian manifold.
This allows us to talk about relationships between samples in the context of the intrinsic structure of $\Omega$; however this is far beyond the scope of what we cover in this post.

Here are some examples of how some random phenomena can be represented as a sample space.
- In the case of tossing a coin once, we might have $\Omega = {\text{heads}, \text{tails}}$.
- If we were studying the annual number of traffic accidents at a busy intersection, we would have $\Omega = \N_0$.
- If we were randomly throwing darts at a square dart board of unit side length, then we could have $\Omega = [0,1] \times [0,1]$, where $\omega \in \Omega$ would represent the location on the board where the dart lands.

As can be seen from the examples, beginning with a set gives us a lot of flexibility in the kinds of randomness we can model.

## Sigma Algebras

Given the definition of an event, we can use the language of set operations to express more complicated outcomes.
For example, in the second example, if $A_n := \\{n\\}$ for every $n \geq 0$, then $A := \bigcup_{n \geq 0} A_{2n}$ is the event that an even number of accidents occur.
On the other hand, in the third example, if $B := [0,1/2] \times [0,1]$ and $C := [0,1] \times [0,1/2]$, then $D := B \cap C = [0,1/2] \times [0,1/2]$ would be the vent that the dart lands in the bottom-left quadrant of the board.

This leads us to the answer of the second question.
In theory, we may choose to allow any set in $\mathcal P(\Omega)$, but since it is useful to speak about events in the way above, it makes sense to define the "good" events in $\Omega$ as follows.

> A **$\sigma$-algebra** is a collection of subsets $\mathcal F \subseteq \mathcal P(\Omega)$ that satisfies the properties
1. $\Omega \in \mathcal F$
1. if $A \in \mathcal F$, then $A^c := \Omega \setminus A \in \mathcal F$
1. if {A_n : n \geq 1} is a sequence of events with $A_n \in \mathcal F$ for every $n \geq 1$, then $\displaystyle A := \bigcup_{n \geq 1} A_n \in \mathcal F$

Note that combining properties 2. and 3. with De Morgan's laws, we obtain
3'. if ${A_n : n \geq 1}$ is a sequence of events with $A_n \in \mathcal F$ for every $n \geq 1$, then $A := \bigcap_{n \geq 1} A_n \in \mathcal F$
and in fact, a $\sigma$-algebra can be equivalently defined using 3'. instead of 3..

Intuitively, $\mathcal F$ represents the kinds of events we are able to observe from a random phenomenon.
At first glance of the definition of a $\sigma$-algebra, it may seem confusing as to why we don't allow for uncountable unions in 3..
Before explaining why it is necessary to restrict ourselves in this way, let's finally define what exactly is a probability.

## Probability measures

> A probability measure (or simply a probability) is a function $\mathbb P : \mathcal F \to [0,1]$ that satisfies the following:
1. (Non-negativity) For any $A \in \mathcal F$, $\mathbb P(A) \geq 0$
2. (Boundedness) $\mathbb P(\Omega) = 1$
3. (Countable additivity) If ${A_n : n \geq 1}$ is a sequence of *disjoint* events with $A_n \in \mathcal F$ for every $n \geq 1$, then $\mathbb P(\bigcup_{n \geq 1} A_n) = \sum_{n \geq 1} \mathbb P(A_n)$

Moreover, given $\Omega$, $\mathcal F$, and $\mathbb P$ as defined above, a triple $(\Omega, \mathcal F, \mathbb P)$ is called a **probability space**.

For example, in the context of tossing a coin once, we may have $\Omega = {H, T}$, $\mathcal F = {\emptyset, {H}, {T}, \Omega}$, and $\mathbb P({H}) = \mathbb P{{T}} = 1/2$.
In addition, in the dart board example, we may have $\Omega = [0,1] \times [0,1]$, $\mathcal F = \mathcal B(\Omega)$ is the set of borel-measurable subsets of $\Omega$, and $\mathbb P = \lambda$ is Lebesgue measure.

If we allow uncountable unions in the definition of a $\sigma$-algebra, then given a probability measure, it is possible to a build an event with probability strictly greater than one.
In other words, it would break our otherwise very nice definition of a probability measure.
We'll explain this shortcoming more in-depth in a later post.

## Conclusion

At last, we finally have the basic ground work on which we can build more probability theory.
To end, here are some properties of $\mathbb P$ which follow directly from the definition and set operation.
It's a good exercise to try proving them!

- $\mathbb P(A^c) = 1 - \mathbb P(A)$
- $\mathbb P(\emptyset) = 0$
- (Monotonicity) if $A \subseteq B$, then $\mathbb P(A) \leq \mathbb P(B)$
- (Sub-additivity) Given a sequence of events ${A_n : n \geq 1 }$ *which may not necessarily be disjoint*, $\mathbb P(\bigcup_{n \geq 1} A_n) \leq \sum_{n \geq 1} \mathbb P(A_n)$
- (Continuity from below) Given ${A_n : n \geq 1}$ with $A_n \subseteq A_{n+1}$ then $\mathbb P(\bigcup_{n \geq 1} A_n) = \lim_{n \to \infty} \mathbb P(A_n)$
- (Continuity from above) Given ${A_n : n \geq 1}$ with $A_{n+1} \subseteq A_n$ then $\mathbb P(\bigcap_{n \geq 1} A_n) = \lim_{n \to \infty} \mathbb P(A_n)$
